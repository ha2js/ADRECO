# 연령-성별 예측 모델 학습

<br>

## 데이터 셋 준비

1. IMDB-WIKI dataset 다운 (얼굴만 자른 버전)  &nbsp; [출처](https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki)

   * **dob:** date of birth (Matlab serial date number)

   * **photo_taken:** year when the photo was taken

   * **full_path:** path to file

   * **gender:** 0 for female and 1 for male, *NaN* if unknown

   * **name:** name of the celebrity

   * face_location: 

     location of the face. To crop the face in Matlab run

     ```python
     img(face_location(2):face_location(4),face_location(1):face_location(3),:))
     ```

   * **face_score:** detector score (the higher the better). *Inf* implies that no face was found in the image and the *face_location* then just returns the entire image

   * **second_face_score:** detector score of the face with the second highest score. This is useful to ignore images with more than one face. *second_face_score* is *NaN* if no second face was detected.

   * **age:** age of the celebrity

     ```python
     [나이,~]=datevec(datenum(wiki.photo_taken,7,1)-wiki.dob) 
     ```

2. 메타 데이터(csv) 생성

   - face_score(검출기 점수)가 1.0 이하 인 데이터 제외

   - 두 명의 얼굴이 존재하는 데이터 제외

   - 나이가 0미만 100초과인 데이터 제외

   - 성별을 알 수 없는 데이터 제외

     ```python
     for i in tqdm(range(sample_num)):
             if face_score[i] < min_score:
                 continue
     
             if (~np.isnan(second_face_score[i])) and second_face_score[i] > 0.0:
                 continue
     
             if ~(0 <= age[i] <= 100):
                 continue
     
             if np.isnan(gender[i]):
                 continue
     
             genders.append(int(gender[i]))
             ages.append(age[i])
             img_paths.append(full_path[i][0])
     
     outputs = dict(genders=genders, ages=ages, img_paths=img_paths)
     output_dir = root_dir.joinpath("meta")
     output_dir.mkdir(exist_ok=True)
     output_path = output_dir.joinpath(f"{db}.csv")
     df = pd.DataFrame(data=outputs)
     df.to_csv(str(output_path), index=False)
     ```
<br>

## config 파일 생성

```yaml
data:
  db: imdb 					            # wiki 데이터셋은 테스트 데이터로 사용

model:
  model_name: EfficientNetB3    # base model
  img_size: 224				          # input img size

train:
  optimizer_name: adam 		      # or sgd
  lr: 0.001					            # 학습률
  epochs: 30				            # 에폭
  batch_size: 16			          # 배치 사이즈
```
<br>

## Generator

```python
csv_path = Path(to_absolute_path(__file__)).parent.joinpath("meta", f"{cfg.data.db}.csv")
df = pd.read_csv(str(csv_path))
train, val = train_test_split(df, random_state=42, test_size=0.1) # train : 90%, val : 10%
train_gen = ImageSequence(cfg, train, "train")
val_gen = ImageSequence(cfg, val, "val")

class ImageSequence(Sequence):
    def __init__(self, cfg, df, mode):
        self.df = df
        self.indices = np.arange(len(df)) # ???
        self.batch_size = cfg.train.batch_size
        self.img_dir = Path(__file__).resolve().parents[1].joinpath("data", f"{cfg.data.db}_crop")
        self.img_size = cfg.model.img_size
        self.mode = mode

    def __getitem__(self, idx):
        sample_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size] # ???
        imgs = []
        genders = []
        ages = []

        for _, row in self.df.iloc[sample_indices].iterrows():
            img = cv2.imread(str(self.img_dir.joinpath(row["img_paths"])))
            img = cv2.resize(img, (self.img_size, self.img_size)) # 224 x 224

            if self.mode == "train":
                img = transforms(image=img)["image"] # 데이터 전처리

            imgs.append(img)
            genders.append(row["genders"])
            ages.append(row["ages"])

        imgs = np.asarray(imgs)
        genders = np.asarray(genders)
        ages = np.asarray(ages)

        return imgs, (genders, ages)

    def __len__(self):
        return len(self.df) // self.batch_size

    def on_epoch_end(self):
        np.random.shuffle(self.indices)
```
<br>

## 데이터 전처리

```python
import albumentations as A # image augmentation library

transforms = A.Compose([
    # ShiftScaleRotate : translate, scale and rotate the input
    A.ShiftScaleRotate(
        shift_limit=0.03125, 	            # 높이와 너비 모두에 대한 이동 계수 범위 (-shift_limit, shift_limit)
        scale_limit=0.20, 		            # 스케일링 팩터 범위 (-scale_limit, scale_limit)
        rotate_limit=20, 		              # 회전 범위 (-rotate_limit, rotate_limit)
        border_mode=cv2.BORDER_CONSTANT,	# 픽셀 외삽 방법을 지정하는 데 사용되는 플래그
        value=0, 				                  # border_mode가 cv2.BORDER_CONSTANT인 경우 패딩 값
        p=1.0 					                  # 변환을 적용할 확률
    ),
    # RandomBrightnessContrast : Randomly change brightness and contrast of the input image
    A.RandomBrightnessContrast(
        brightness_limit=0.2, 		        # 밝기를 변경하기 위한 요소 범위 (-limit, limit)
        contrast_limit=0.2, p=0.5	        # 대비를 변경하기 위한 요소 범위 (-limit, limit)
    ), : 
    # HorizontalFlip : Flip the input horizontally around the y-axis
    A.HorizontalFlip(
        p=0.5		                          # 변환을 적용할 확률
    )
])
```
<br>

## 모델 load

```python
model = get_model(cfg)

def get_model(cfg):
    base_model = getattr(applications, cfg.model.model_name)(
        include_top=False,
        input_shape=(cfg.model.img_size, cfg.model.img_size, 3),
        pooling="avg"
    )
    features = base_model.output
    pred_gender = Dense(units=2, activation="softmax", name="pred_gender")(features)
    pred_age = Dense(units=101, activation="softmax", name="pred_age")(features)
    model = Model(inputs=base_model.input, outputs=[pred_gender, pred_age])
    return model
```
<br>

## Optimizer 설정

```python
opt = get_optimizer(cfg)

def get_optimizer(cfg):
    if cfg.train.optimizer_name == "sgd":
        return SGD(lr=cfg.train.lr, momentum=0.9, nesterov=True)
    elif cfg.train.optimizer_name == "adam":
        return Adam(lr=cfg.train.lr)
    else:
        raise ValueError("optimizer name should be 'sgd' or 'adam'")
```
<br>

## Scheduler 설정

```python
scheduler = get_scheduler(cfg)

def get_scheduler(cfg):
    class Schedule:
        def __init__(self, nb_epochs, initial_lr):
            self.epochs = nb_epochs
            self.initial_lr = initial_lr

        def __call__(self, epoch_idx):
            if epoch_idx < self.epochs * 0.25:
                return self.initial_lr
            elif epoch_idx < self.epochs * 0.50:
                return self.initial_lr * 0.2
            elif epoch_idx < self.epochs * 0.75:
                return self.initial_lr * 0.04
            return self.initial_lr * 0.008
    return Schedule(cfg.train.epochs, cfg.train.lr)
```
<br>

## 학습 모델 컴파일

```python
model.compile(optimizer=opt,
              loss=["sparse_categorical_crossentropy", "sparse_categorical_crossentropy"],
              metrics=['accuracy'])
```
<br>

## 체크 포인트 경로 지정

```python
checkpoint_dir = Path(to_absolute_path(__file__)).parent.joinpath("checkpoint")
checkpoint_dir.mkdir(exist_ok=True)
filename = "_".join([cfg.model.model_name,
                     str(cfg.model.img_size),
                     "weights.{epoch:02d}-{val_loss:.2f}.hdf5"])
```
<br>

## 콜백 함수

```python
callbacks.extend([
    LearningRateScheduler(schedule=scheduler),
    ModelCheckpoint(str(checkpoint_dir) + "/" + filename,
                    monitor="val_loss", 		  # val_loss 값이 개선되었을 때 호출
                    verbose=1, 					      # 로그 출력
                    save_best_only=True, 		  #가장 best 값만 저장
                    mode="auto") 				      # auto는 알아서 best를 찾음. min/max
])
```
<br>

## 학습

```python
model.fit(
    train_gen, 
    epochs=cfg.train.epochs, 
    callbacks=callbacks, 
    validation_data=val_gen
)
```

