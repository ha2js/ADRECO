# 연령-성별 예측 모델 학습

<br>

## 데이터 셋 준비

1. IMDB-WIKI dataset 다운 (얼굴만 자른 버전)  &nbsp; [출처](https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki)

   * **dob:** date of birth (Matlab serial date number)

   * **photo_taken:** year when the photo was taken

   * **full_path:** path to file

   * **gender:** 0 for female and 1 for male, *NaN* if unknown

   * **name:** name of the celebrity

   * face_location: 

     location of the face. To crop the face in Matlab run

     ```python
     img(face_location(2):face_location(4),face_location(1):face_location(3),:))
     ```

   * **face_score:** detector score (the higher the better). *Inf* implies that no face was found in the image and the *face_location* then just returns the entire image

   * **second_face_score:** detector score of the face with the second highest score. This is useful to ignore images with more than one face. *second_face_score* is *NaN* if no second face was detected.

   * **age:** age of the celebrity

     ```python
     [나이,~]=datevec(datenum(wiki.photo_taken,7,1)-wiki.dob) 
     ```

2. 메타 데이터(csv) 생성

   - face_score(검출기 점수)가 1.0 이하 인 데이터 제외

   - 두 명의 얼굴이 존재하는 데이터 제외

   - 나이가 0미만 100초과인 데이터 제외

   - 성별을 알 수 없는 데이터 제외

     ```python
     for i in tqdm(range(sample_num)):
             if face_score[i] < min_score:
                 continue
     
             if (~np.isnan(second_face_score[i])) and second_face_score[i] > 0.0:
                 continue
     
             if ~(0 <= age[i] <= 100):
                 continue
     
             if np.isnan(gender[i]):
                 continue
     
             genders.append(int(gender[i]))
             ages.append(age[i])
             img_paths.append(full_path[i][0])
     
     outputs = dict(genders=genders, ages=ages, img_paths=img_paths)
     output_dir = root_dir.joinpath("meta")
     output_dir.mkdir(exist_ok=True)
     output_path = output_dir.joinpath(f"{db}.csv")
     df = pd.DataFrame(data=outputs)
     df.to_csv(str(output_path), index=False)
     ```
<br>

## config 파일 생성

```yaml
data:
  db: imdb                      # wiki 데이터셋은 테스트 데이터로 사용

model:
  model_name: EfficientNetB3    # base model
  img_size: 224                 # input img size

train:
  optimizer_name: adam          # or sgd
  lr: 0.001                     # 학습률
  epochs: 30                    # 에폭
  batch_size: 16                # 배치 사이즈
```
<br>

## Generator


- 초기화함수(__ init__)
- 길이함수(__ len__)
- index값에 따라 데이터를 반환하는 함수(__ getitem__)
- 한 epoch이 끝날 때 마다 실행하는 함수(on_epoch_end)
<br>

### 1) __ init__(초기화함수)

```python
class ImageSequence(Sequence):
    def __init__(self, cfg, df, mode):
        self.df = df
        self.indices = np.arange(len(df))
        self.batch_size = cfg.train.batch_size
        self.img_dir = Path(__file__).resolve().parents[1].joinpath("data", f"{cfg.data.db}_crop")
        self.img_size = cfg.model.img_size
        self.mode = mode
```
<br>

### 2) __ len__(길이함수)

```python
    def __len__(self):
        return len(self.df) // self.batch_size
```
- 데이터 로더의 전체길이를 반환하는 함수

- loader=data/batch_size

- data=50000 batch_size=100 => loader=500
<br>

### 3) __ get__item(index값에 따라 데이터를 반환하는 함수)

```python 
def __getitem__(self, idx):
        sample_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]
        imgs = []
        genders = []
        ages = []

        for _, row in self.df.iloc[sample_indices].iterrows():
            img = cv2.imread(str(self.img_dir.joinpath(row["img_paths"])))
            img = cv2.resize(img, (self.img_size, self.img_size)) # 224 x 224

            if self.mode == "train":
                img = transforms(image=img)["image"] # 데이터 전처리

            imgs.append(img)
            genders.append(row["genders"])
            ages.append(row["ages"])

        imgs = np.asarray(imgs)
        genders = np.asarray(genders)
        ages = np.asarray(ages)

        return imgs, (genders, ages)
```
- self .indices는 전체데이터의 index배열 (데이터가 10개인 경우 0~9번째의 index배열)
- indices는 get_item을 호출한 idx에 맞는 배치사이즈만큼의 index배열

self.indices=[0 1 2 3 4 5 6 7 8 9 ] batch_size=2일때,

__ getitem(0)__ 호출시 indices는 [0,1]이 되어 각 index에 맞는 데이터[0,1] 반환

__ getitem(1)__ 호출시 indices는 [2,3]이 되어 각 index에 맞는 데이터[2,3] 반환

<br>

### 4) on_epoch_end(한 epoch이 끝날 때마다 실행하는 함수)

```python
def on_epoch_end(self):
        np.random.shuffle(self.indices)
```
- 단순하게 index를 shuffle하는 함수
- shufffle을 통해 각 batch마다 같은 데이터셋을 학습시키는 것을 방지하여 모델을 좀 더 robust하게 만든다.

머신러닝에서 일반화(generalization)는 일부 특정 데이터만 잘 설명하는(=overfitting) 것이 아니라 범용적인 데이터도 적합한 모델을 의미한다. 즉, 잘 일반화하기 위해서는 이상치나 노이즈가 들어와도 크게 흔들리지 않아야(=robust) 한다.

<br>

## 데이터 전처리

```python
import albumentations as A # image augmentation library

transforms = A.Compose([
    # ShiftScaleRotate : translate, scale and rotate the input
    A.ShiftScaleRotate(
        shift_limit=0.03125,              # 높이와 너비 모두에 대한 이동 계수 범위 (-shift_limit, shift_limit)
        scale_limit=0.20,                 # 스케일링 팩터 범위 (-scale_limit, scale_limit)
        rotate_limit=20,                  # 회전 범위 (-rotate_limit, rotate_limit)
        border_mode=cv2.BORDER_CONSTANT,  # 픽셀 외삽 방법을 지정하는 데 사용되는 플래그
        value=0,                          # border_mode가 cv2.BORDER_CONSTANT인 경우 패딩 값
        p=1.0,                            # 변환을 적용할 확률
    ),
    # RandomBrightnessContrast : Randomly change brightness and contrast of the input image
    A.RandomBrightnessContrast(
        brightness_limit=0.2,             # 밝기를 변경하기 위한 요소 범위 (-limit, limit)
        contrast_limit=0.2, p=0.5         # 대비를 변경하기 위한 요소 범위 (-limit, limit)
    ), : 
    # HorizontalFlip : Flip the input horizontally around the y-axis
    A.HorizontalFlip(
        p=0.5                             # 변환을 적용할 확률
    )
])
```
<br>

## 모델 load

```python
model = get_model(cfg)

def get_model(cfg):
    base_model = getattr(applications, cfg.model.model_name)(
        include_top=False,
        input_shape=(cfg.model.img_size, cfg.model.img_size, 3),
        pooling="avg"
    )
    features = base_model.output
    pred_gender = Dense(units=2, activation="softmax", name="pred_gender")(features)
    pred_age = Dense(units=101, activation="softmax", name="pred_age")(features)
    model = Model(inputs=base_model.input, outputs=[pred_gender, pred_age])
    return model
```

### * EfficientNet model

- <b> EfficientNet은 Image Classfication Task에 대해서 기존보다 훨씬 적은 파라미터수로 더욱 좋은 성능을 내서 State-Of-The-Art(SOTA=최신기술)를 달성한 모델</b>
<br>

기존의 연구들은, ConvNet(CNN)의 성능을 올리기 위해서 Scaling up시도를 많이했다.
Scale-up의 방법은 3가지가 있다.

1. 망의 depth를 늘리는것(=layer의 개수를 늘림) : 가장 흔한 방법
2. channel width를 늘리는것(=filter의 개수를 (channel의 개수를)늘림) : 기존의 연구에 따르면 width 를 넓게할수록 미세한 정보들이 더 많이 담긴다고 한다.
3. 입력 이미지의 resolution을 올리는 것 (input image의 해상도를 높임) : 실험을 통해 더 큰 사이즈의 이미지를 넣으면 성능이 올라감을 확인했다고 한다.

EfficientNet은 세가지 방법에 대한 최적의 조합을 AutoML을 통해 찾은 모델이다. 그러므로 3가지를 효율적으로 조절할 수 있는 compound scaling방법을 제안한다. 하지만 "효율적"이라는 단어를 쓴 만큼 제한된 resource 의 범위에서 최적의 조합을 고려한다.
<br>
이를 통해 기존보다 훨씬 적은 파라미터수로 더욱 좋은 성능을 내서 State-of-The-Art(SOTA=최신기술) 달성할 수 있던 것이다.


<br>

## Optimizer 설정

```python
opt = get_optimizer(cfg)

def get_optimizer(cfg):
    if cfg.train.optimizer_name == "sgd":
        return SGD(lr=cfg.train.lr, momentum=0.9, nesterov=True)
    elif cfg.train.optimizer_name == "adam":
        return Adam(lr=cfg.train.lr)
    else:
        raise ValueError("optimizer name should be 'sgd' or 'adam'")
```
<br>

경사 하강법은 정확하게 가중치를 찾아가지만 가중치를 변경할때마다 전체 데이터에 대해 미분해야 하므로 계산량이 매우 많다.
즉 많은 계산량때문에 속도가 느리고, 추가적으로 최적해를 찾기 전 학습을 멈출 수도 있음. 이러한 점을 보안한 다양한 경사 하강법이 등장

#### 1) SGD(확률적 경사 하강법) - 스텝사이즈
- 전부 다 한걸음은 너무 오래걸리니까 조금만 보고 빨리 판단한다! 같은 시간에 더 많이 가기!
- 확률적 경사 하강법(Stochastic Gradient Descent)는 경사 하강법과 다르게 한번 학습할 때 모든 데이터에 대해 가중치를 조절하는 것이 아니라, 램덤하게 추출한 일부 데이터에 대해 가중치를 조절.
- 결과적으로 속도는 개선되었지만 최적 해의 정확도는 낮다.

#### 2) Momentum(모멘텀) - 스텝방향
- 스텝 계산해서 움직인 후 , 아까내려온 관성 방향으로 또 가자!
 - 모멘텀(momentum)이란 단어는 관성, 탄력, 가속도라는 뜻
 - 모멘텀 SGD는 경사 하강법에 관성을 더해 주는 것. 
 - 경사 하강법과 마찬가지로 매번 기울기를 구하지만, 가중치를 수정하기전 이전 수정 방향(+,-)를 참고하여 같은 방향으로 일정한 비율만 수정되게 하는 방법. 
 - 수정이 양(+) 방향, 음(-) 방향 순차적으로 일어나는 지그재그 현상이 줄어들고, 이전 이동 값을 고려해여 일정 비율만큼 다음 값을 결정하므로 관성의 효과를 낸다.
 
#### 3) Adaptive Gradient (AdaGrad) - 스텝사이즈
- 안가본 곳은 빠르게 걸어 훑고 많이 가본곳은 잘 아니까 갈수록 보폭을 줄여 세밀히 탐색
- AdaGrad는 2011년에 제안된 SGD 기반의 알고리즘
- 최적화 과정을 효율적으로 만들기 위해 고정된 learning rate가 아니라 각각의 변수마다 적합한 learning rate를 자동으로 설정. 
- AdaGrad의 전략은 지금까지 변화가 많았던 변수들은 optimum의 근처에 있을 확률이 높기 때문에 learning rate를 작게 함으로써 더욱 세밀하게 update가 되도록 만들고, 변화가 적었던 변수들은 optimum에서 멀리 벗어나 있을 확률이 높기 때문에 learning rate를 크게 함으로써 더욱 빠르게 optimum으로 수렴하도록 만드는 것이다.

<br>

## Scheduler 설정

```python
scheduler = get_scheduler(cfg)

def get_scheduler(cfg):
    class Schedule:
        def __init__(self, nb_epochs, initial_lr):
            self.epochs = nb_epochs
            self.initial_lr = initial_lr

        def __call__(self, epoch_idx):
            if epoch_idx < self.epochs * 0.25:
                return self.initial_lr
            elif epoch_idx < self.epochs * 0.50:
                return self.initial_lr * 0.2
            elif epoch_idx < self.epochs * 0.75:
                return self.initial_lr * 0.04
            return self.initial_lr * 0.008
    return Schedule(cfg.train.epochs, cfg.train.lr)
```
<br>

## 학습 모델 컴파일

```python
model.compile(optimizer=opt,
              loss=["sparse_categorical_crossentropy", "sparse_categorical_crossentropy"],
              metrics=['accuracy'])
```
<br>

## 체크 포인트 경로 지정

```python
checkpoint_dir = Path(to_absolute_path(__file__)).parent.joinpath("checkpoint")
checkpoint_dir.mkdir(exist_ok=True)
filename = "_".join([cfg.model.model_name,
                     str(cfg.model.img_size),
                     "weights.{epoch:02d}-{val_loss:.2f}.hdf5"])
```

- Checkpoint는 학습된 모델의 Variable값을 저장하는 파일
- 학습시킨 딥러닝 모델을 저장
<br>

## 콜백 함수

```python
callbacks.extend([
    LearningRateScheduler(schedule=scheduler),
    ModelCheckpoint(str(checkpoint_dir) + "/" + filename,
                    monitor="val_loss",       # val_loss 값이 개선되었을 때 호출
                    verbose=1,                # 로그 출력
                    save_best_only=True,      #가장 best 값만 저장
                    mode="auto")              # auto는 알아서 best를 찾음. min/max
])
```
<br>

## 학습

```python
model.fit(
    train_gen, 
    epochs=cfg.train.epochs, 
    callbacks=callbacks, 
    validation_data=val_gen
)
```
<br>

## 검증

```python
faces = np.empty((batch_size, img_size, img_size, 3))
ages = []
image_names = []

for i, image_path in tqdm(enumerate(image_paths)):
    faces[i % batch_size] = cv2.resize(cv2.imread(str(image_path), 1), (img_size, img_size))
    image_names.append(image_path.name[:-9])

    if (i + 1) % batch_size == 0 or i == len(image_paths) - 1:
        results = model.predict(faces)
        ages_out = np.arange(0, 101).reshape(101, 1)
        predicted_ages = results[1].dot(ages_out).flatten()
        ages += list(predicted_ages)
        # len(ages) can be larger than len(image_names) due to the last batch, but it's ok.

name2age = {image_names[i]: ages[i] for i in range(len(image_names))}
df = pd.read_csv(str(gt_valid_path))
appa_abs_error = 0.0
real_abs_error = 0.0

for i, row in df.iterrows():
    appa_abs_error += abs(name2age[row.file_name] - row.apparent_age_avg)
    real_abs_error += abs(name2age[row.file_name] - row.real_age)

print("MAE Apparent: {}".format(appa_abs_error / len(image_names)))
print("MAE Real: {}".format(real_abs_error / len(image_names)))
```
<br>

## 성능 검증 지표
MAE(평균절대오차)

<br>
